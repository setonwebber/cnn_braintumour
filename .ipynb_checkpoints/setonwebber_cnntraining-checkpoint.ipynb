{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T02:55:34.844098Z",
     "iopub.status.busy": "2023-10-20T02:55:34.843638Z",
     "iopub.status.idle": "2023-10-20T02:55:58.844167Z",
     "shell.execute_reply": "2023-10-20T02:55:58.843124Z",
     "shell.execute_reply.started": "2023-10-20T02:55:34.844061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in c:\\users\\seton\\anaconda3\\envs\\ml3.7\\lib\\site-packages (0.5.4)\n"
     ]
    }
   ],
   "source": [
    "! pip install imutils\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import imutils\n",
    "import pathlib\n",
    "import time\n",
    "import PIL as pil\n",
    "import shutil\n",
    "\n",
    "IMAGE_SIZE = (256, 256)\n",
    "BASE_LR = 1e-3\n",
    "EPOCH = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing datasets\n",
    "\n",
    "for this dataset\n",
    "https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T02:55:58.847183Z",
     "iopub.status.busy": "2023-10-20T02:55:58.845778Z",
     "iopub.status.idle": "2023-10-20T02:55:58.856984Z",
     "shell.execute_reply": "2023-10-20T02:55:58.855811Z",
     "shell.execute_reply.started": "2023-10-20T02:55:58.847152Z"
    }
   },
   "outputs": [],
   "source": [
    "def crop_img(img, image_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Finds the extreme points on the image and crops the rectangular out of them\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "    # threshold the image, then perform a series of erosions +\n",
    "    # dilations to remove any small regions of noise\n",
    "    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh = cv2.erode(thresh, None, iterations=2)\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\n",
    "    # find contours in thresholded image, then grab the largest one\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "    # find the extreme points\n",
    "    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
    "    extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
    "    extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
    "    extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
    "    ADD_PIXELS = 0\n",
    "    new_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()\n",
    "    \n",
    "    # resize image\n",
    "    new_img = cv2.resize(new_img, image_size)\n",
    "    \n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T02:55:58.859593Z",
     "iopub.status.busy": "2023-10-20T02:55:58.858448Z",
     "iopub.status.idle": "2023-10-20T02:55:58.875565Z",
     "shell.execute_reply": "2023-10-20T02:55:58.874356Z",
     "shell.execute_reply.started": "2023-10-20T02:55:58.859541Z"
    }
   },
   "outputs": [],
   "source": [
    "def image_preprocessing(source_dir, saved_root_dir, image_size=(256,256), channels=3):\n",
    "    if not os.path.exists(source_dir):\n",
    "        raise Exception(f\"source directory: {source_dir} does not exists\")\n",
    "    else:\n",
    "        if not os.path.isdir(source_dir):\n",
    "            raise Exception(f\"source directory: {source_dir} is not a directory\")\n",
    "            \n",
    "    if not os.path.exists(saved_root_dir):\n",
    "        os.makedirs(saved_root_dir)\n",
    "        \n",
    "    source_dir_path = pathlib.Path(source_dir)\n",
    "    \n",
    "    # transform and save\n",
    "    for p in source_dir_path.iterdir():\n",
    "        dir_name = str(p).split(\"/\")[-1]\n",
    "        for fp in p.iterdir():\n",
    "            filename = str(fp).split(\"/\")[-1]\n",
    "            img = tf.io.read_file(str(fp))\n",
    "            img = tf.image.decode_jpeg(img, channels=channels)\n",
    "            img = crop_img(img.numpy(), image_size)\n",
    "            img = pil.Image.fromarray(img)\n",
    "            saved_dist_dir = os.path.join(saved_root_dir, dir_name)\n",
    "            if not os.path.exists(saved_dist_dir):\n",
    "                os.makedirs(saved_dist_dir)\n",
    "            img_dist_path = saved_dist_dir+\"/\"+f\"{filename}\"\n",
    "            img.save(img_dist_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T02:55:58.878682Z",
     "iopub.status.busy": "2023-10-20T02:55:58.87806Z",
     "iopub.status.idle": "2023-10-20T02:57:17.436613Z",
     "shell.execute_reply": "2023-10-20T02:57:17.435624Z",
     "shell.execute_reply.started": "2023-10-20T02:55:58.878652Z"
    }
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "source directory: /input/Training does not exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18156\\864421527.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m image_preprocessing(\"/input/Training\",\n\u001b[0;32m      2\u001b[0m                    \u001b[1;34m\"/working/Training\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                    image_size=IMAGE_SIZE)\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m image_preprocessing(\"/input/Testing\",\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18156\\265149162.py\u001b[0m in \u001b[0;36mimage_preprocessing\u001b[1;34m(source_dir, saved_root_dir, image_size, channels)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mimage_preprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaved_root_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"source directory: {source_dir} does not exists\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: source directory: /input/Training does not exists"
     ]
    }
   ],
   "source": [
    "image_preprocessing(\"/input/Training\",\n",
    "                   \"/working/Training\",\n",
    "                   image_size=IMAGE_SIZE)\n",
    "\n",
    "image_preprocessing(\"/input/Testing\",\n",
    "                   \"/working/Testing\",\n",
    "                   image_size=IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuJXo3b-f7PX"
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T02:57:17.439342Z",
     "iopub.status.busy": "2023-10-20T02:57:17.438048Z",
     "iopub.status.idle": "2023-10-20T02:57:17.444866Z",
     "shell.execute_reply": "2023-10-20T02:57:17.443641Z",
     "shell.execute_reply.started": "2023-10-20T02:57:17.439308Z"
    },
    "id": "nLLkxrD0ivtJ"
   },
   "outputs": [],
   "source": [
    "root_dir_path = \"/kaggle/working/brain-tumor-mri-dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-20T02:57:17.447132Z",
     "iopub.status.busy": "2023-10-20T02:57:17.446715Z",
     "iopub.status.idle": "2023-10-20T02:57:17.986948Z",
     "shell.execute_reply": "2023-10-20T02:57:17.985827Z",
     "shell.execute_reply.started": "2023-10-20T02:57:17.447098Z"
    },
    "id": "JZP7jZ4Vf7Pc",
    "outputId": "8ebbd760-2c09-4d05-fc43-05965d0d47a1"
   },
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(os.path.join(root_dir_path, \"Training\"),\n",
    "                                                               label_mode=\"categorical\",\n",
    "                                                                batch_size=16,\n",
    "                                                                image_size=IMAGE_SIZE,\n",
    "                                                                seed=42)\n",
    "\n",
    "test_ds, val_ds = tf.keras.utils.image_dataset_from_directory(os.path.join(root_dir_path, \"Testing\"),\n",
    "                                                               label_mode=\"categorical\",\n",
    "                                                                image_size=IMAGE_SIZE,\n",
    "                                                                seed=42,\n",
    "                                                                validation_split=0.2,\n",
    "                                                                subset=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T02:57:17.989692Z",
     "iopub.status.busy": "2023-10-20T02:57:17.98839Z",
     "iopub.status.idle": "2023-10-20T02:57:17.995683Z",
     "shell.execute_reply": "2023-10-20T02:57:17.994676Z",
     "shell.execute_reply.started": "2023-10-20T02:57:17.989648Z"
    },
    "id": "8Q3yArLCf7Pe",
    "outputId": "6a76410d-f086-4531-b6cc-6599f0fb2512"
   },
   "outputs": [],
   "source": [
    "print(train_ds.class_names)\n",
    "print(test_ds.class_names)\n",
    "\n",
    "cls_to_id = {c:i for i, c in enumerate(train_ds.class_names)}\n",
    "print(cls_to_id)\n",
    "id_to_cls = {i:c for i, c in enumerate(train_ds.class_names)}\n",
    "print(id_to_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T02:57:17.997367Z",
     "iopub.status.busy": "2023-10-20T02:57:17.997017Z",
     "iopub.status.idle": "2023-10-20T02:57:18.012637Z",
     "shell.execute_reply": "2023-10-20T02:57:18.011428Z",
     "shell.execute_reply.started": "2023-10-20T02:57:17.997342Z"
    },
    "id": "uPjSeagdf7Pf"
   },
   "outputs": [],
   "source": [
    "with open(\"class_to_id.txt\", \"w\") as f:\n",
    "    for k, v in cls_to_id.items():\n",
    "        f.write(f\"{k}\\t{v}\\n\")\n",
    "\n",
    "with open(\"id_to_class.txt\", \"w\") as f:\n",
    "    for k, v in id_to_cls.items():\n",
    "        f.write(f\"{k}\\t{v}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T02:57:18.015065Z",
     "iopub.status.busy": "2023-10-20T02:57:18.014076Z",
     "iopub.status.idle": "2023-10-20T02:57:18.025289Z",
     "shell.execute_reply": "2023-10-20T02:57:18.023933Z",
     "shell.execute_reply.started": "2023-10-20T02:57:18.015027Z"
    },
    "id": "XLvvdUm6f7Pf",
    "outputId": "b2aa2166-813d-42a6-fb31-2d166c69afbf"
   },
   "outputs": [],
   "source": [
    "with open(\"class_to_id.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        cls, label = line.replace(\"\\n\",\"\").split(\"\\t\")\n",
    "        print(cls, int(label))\n",
    "print(\"\\n\")\n",
    "with open(\"id_to_class.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        label, cls = line.replace(\"\\n\",\"\").split(\"\\t\")\n",
    "        print(int(label), cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T02:57:18.029276Z",
     "iopub.status.busy": "2023-10-20T02:57:18.028941Z",
     "iopub.status.idle": "2023-10-20T02:57:21.814198Z",
     "shell.execute_reply": "2023-10-20T02:57:21.81292Z",
     "shell.execute_reply.started": "2023-10-20T02:57:18.029252Z"
    }
   },
   "outputs": [],
   "source": [
    "def class_weight_from_one_hot(ds):\n",
    "    class_labels = []\n",
    "    if ds.__class__.__name__ == \"_BatchDataset\":\n",
    "        ds = ds.unbatch()\n",
    "    \n",
    "    for _, onehot in ds:\n",
    "        class_labels.append(tf.argmax(onehot).numpy())\n",
    "    \n",
    "    unique_classes = np.unique(class_labels)\n",
    "    class_weights = compute_class_weight(class_weight=\"balanced\", \n",
    "                                         classes=unique_classes,\n",
    "                                         y=class_labels)\n",
    "    return {i:w for i, w in enumerate(class_weights)}\n",
    "\n",
    "    \n",
    "class_weights = class_weight_from_one_hot(train_ds)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T02:57:21.81566Z",
     "iopub.status.busy": "2023-10-20T02:57:21.815344Z",
     "iopub.status.idle": "2023-10-20T02:57:22.265246Z",
     "shell.execute_reply": "2023-10-20T02:57:22.26423Z",
     "shell.execute_reply.started": "2023-10-20T02:57:21.815635Z"
    },
    "id": "f2EnMhWWf7Pf",
    "outputId": "b33194ba-2d4f-4efa-ce72-84677d5d64ba"
   },
   "outputs": [],
   "source": [
    "for images, labels in train_ds.take(1):\n",
    "    image, label = images[0], labels[0]\n",
    "    plt.figure()\n",
    "    plt.imshow(tf.cast(image, tf.uint8))\n",
    "    plt.title(train_ds.class_names[tf.argmax(label).numpy()])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bFFWroJEf7Pg"
   },
   "source": [
    "# Model \n",
    "\n",
    "EfficientNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T02:57:45.555955Z",
     "iopub.status.busy": "2023-10-20T02:57:45.555549Z",
     "iopub.status.idle": "2023-10-20T02:57:45.563552Z",
     "shell.execute_reply": "2023-10-20T02:57:45.562776Z",
     "shell.execute_reply.started": "2023-10-20T02:57:45.555927Z"
    },
    "id": "rSnGHGNxf7Ph"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input_shape = (IMAGE_SIZE[0], IMAGE_SIZE[1], 3)\n",
    "    input = tf.keras.layers.Input(shape=input_shape, name=\"input\")\n",
    "    x = tf.keras.layers.RandomFlip(\"horizontal_and_vertical\")(input)\n",
    "    x = tf.keras.layers.RandomBrightness(0.2)(x)\n",
    "    x = tf.keras.layers.RandomZoom(0.2, 0.2)(x)\n",
    "    x = tf.keras.layers.RandomTranslation(0.2, 0.2)(x)\n",
    "    x = tf.keras.layers.RandomRotation(0.2)(x)\n",
    "    x = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(input_shape=input_shape,\n",
    "                                                               include_top=False)(x)\n",
    "    x = tf.keras.layers.GlobalMaxPooling2D(name=\"max_pooling\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    output = tf.keras.layers.Dense(4, \"softmax\", name=\"output\")(x)\n",
    "\n",
    "    return tf.keras.Model(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T02:57:48.439379Z",
     "iopub.status.busy": "2023-10-20T02:57:48.438427Z",
     "iopub.status.idle": "2023-10-20T02:57:54.689529Z",
     "shell.execute_reply": "2023-10-20T02:57:54.68851Z",
     "shell.execute_reply.started": "2023-10-20T02:57:48.43934Z"
    }
   },
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.summary(show_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T02:57:28.026466Z",
     "iopub.status.busy": "2023-10-20T02:57:28.026137Z",
     "iopub.status.idle": "2023-10-20T02:57:28.104806Z",
     "shell.execute_reply": "2023-10-20T02:57:28.103652Z",
     "shell.execute_reply.started": "2023-10-20T02:57:28.026428Z"
    }
   },
   "outputs": [],
   "source": [
    "pretrain_model_layer = 6\n",
    "\n",
    "# freeze pretrain model\n",
    "model.layers[pretrain_model_layer].trainable = False\n",
    "model.summary(show_trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XEQ_expf7Ph"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-19T09:44:21.477023Z",
     "iopub.status.busy": "2023-10-19T09:44:21.476752Z",
     "iopub.status.idle": "2023-10-19T09:44:21.493202Z",
     "shell.execute_reply": "2023-10-19T09:44:21.492255Z",
     "shell.execute_reply.started": "2023-10-19T09:44:21.476999Z"
    },
    "id": "5pcprZcrf7Pi"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "             optimizer=tf.keras.optimizers.Adam(BASE_LR),\n",
    "             metrics=[\"categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-19T09:44:21.494385Z",
     "iopub.status.busy": "2023-10-19T09:44:21.494148Z",
     "iopub.status.idle": "2023-10-19T09:44:55.04461Z",
     "shell.execute_reply": "2023-10-19T09:44:55.043846Z",
     "shell.execute_reply.started": "2023-10-19T09:44:21.494364Z"
    },
    "id": "SUeHf5f6f7Pi",
    "outputId": "7dc8823e-3122-44c8-f802-54474e1fa55d"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "cbs = [\n",
    "    ReduceLROnPlateau(patience=3, min_lr=1e-6),\n",
    "    EarlyStopping(patience=8, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "history = model.fit(train_ds,\n",
    "                   epochs=EPOCH,\n",
    "                   validation_data=val_ds,\n",
    "                   class_weight=class_weights,\n",
    "                   callbacks=cbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-19T09:44:55.062264Z",
     "iopub.status.busy": "2023-10-19T09:44:55.061973Z",
     "iopub.status.idle": "2023-10-19T09:44:55.092438Z",
     "shell.execute_reply": "2023-10-19T09:44:55.091479Z",
     "shell.execute_reply.started": "2023-10-19T09:44:55.062241Z"
    }
   },
   "outputs": [],
   "source": [
    "# unfreeze top layers for training on pretrain model\n",
    "fine_tune_at = 100\n",
    "pretrain_model = model.layers[pretrain_model_layer]\n",
    "pretrain_model.trainable = True\n",
    "for layer in pretrain_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "for layer in pretrain_model.layers:    \n",
    "    print(layer.name, layer.output.shape, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-19T09:44:55.09377Z",
     "iopub.status.busy": "2023-10-19T09:44:55.093549Z",
     "iopub.status.idle": "2023-10-19T09:44:55.11089Z",
     "shell.execute_reply": "2023-10-19T09:44:55.110179Z",
     "shell.execute_reply.started": "2023-10-19T09:44:55.09375Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "             optimizer=tf.keras.optimizers.Adam(BASE_LR/10),\n",
    "             metrics=[\"categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-19T09:44:55.112228Z",
     "iopub.status.busy": "2023-10-19T09:44:55.111942Z"
    }
   },
   "outputs": [],
   "source": [
    "last_epoch = history.epoch[-1]\n",
    "\n",
    "history_fine = model.fit(train_ds,\n",
    "                           epochs=last_epoch+100,\n",
    "                           initial_epoch=last_epoch,\n",
    "                           validation_data=val_ds,\n",
    "                           class_weight=class_weights,\n",
    "                           callbacks=cbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtsQpqUwf7Pi"
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yrkGLNK3gEgU",
    "outputId": "e4b86706-e540-48fe-8cda-e946d366f4e0"
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4_ENRAOf7Pi",
    "outputId": "41c13046-8527-41e6-8f8c-e72d7b812d35"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "epochs = list(range(len(history.history[\"loss\"])))\n",
    "plt.plot(epochs, history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(epochs, history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.xticks(ticks=epochs)\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kkHed8tKf7Pi",
    "outputId": "61e5d5f4-e1db-4273-b403-718df2bbabd7"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "epochs = list(range(len(history.history[\"categorical_accuracy\"])))\n",
    "plt.plot(epochs, history.history[\"categorical_accuracy\"], label=\"train_accuracy\")\n",
    "plt.plot(epochs, history.history[\"val_categorical_accuracy\"], label=\"val_accuracy\")\n",
    "plt.xticks(ticks=epochs)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "epochs = list(range(len(history_fine.history[\"loss\"])))\n",
    "plt.plot(epochs, history_fine.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(epochs, history_fine.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.xticks(ticks=epochs)\n",
    "plt.title(\"Fine-Tune Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "epochs = list(range(len(history_fine.history[\"categorical_accuracy\"])))\n",
    "plt.plot(epochs, history_fine.history[\"categorical_accuracy\"], label=\"train_accuracy\")\n",
    "plt.plot(epochs, history_fine.history[\"val_categorical_accuracy\"], label=\"val_accuracy\")\n",
    "plt.xticks(ticks=epochs)\n",
    "plt.title(\"Fine-Tune Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tQBmegNFf7Pj",
    "outputId": "132eac7a-fac1-4acb-ea20-739c2206dc74"
   },
   "outputs": [],
   "source": [
    "# inspect model performance\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def classi_report(test_ds):\n",
    "    if test_ds.__class__.__name__ == \"_BatchDataset\":\n",
    "        test_ds = test_ds.unbatch()\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    pred_times = []\n",
    "    \n",
    "    for img, one_hot_label in test_ds:\n",
    "        label = tf.argmax(one_hot_label).numpy()\n",
    "        t1 = time.time()\n",
    "        output = model.predict(tf.expand_dims(img, axis=0), verbose=0)\n",
    "        t2 = time.time()\n",
    "        pred = tf.squeeze(output)\n",
    "        pred = tf.argmax(pred).numpy()\n",
    "        y_true.append(label)\n",
    "        y_pred.append(pred)\n",
    "        pred_times.append(t2-t1)\n",
    "    \n",
    "    print(f\"average prediction time: {np.mean(pred_times)} seconds\")\n",
    "    return classification_report(y_true, y_pred)\n",
    "\n",
    "print(classi_report(test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCvyz1kvf7Pj"
   },
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7aKjai6Vf7Pj",
    "outputId": "6f02d2f4-992f-43a9-8c55-285935be335a"
   },
   "outputs": [],
   "source": [
    "model.save(\"brain_tumor_detector.keras\")\n",
    "model.save(\"brain_tumor_detector.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize model for tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for float fallback quantization\n",
    "def representative_data_gen():\n",
    "    rep_ds = train_ds\n",
    "    if rep_ds.__class__.__name__ == \"_BatchDataset\":\n",
    "        rep_ds = rep_ds.unbatch()\n",
    "        rep_ds = rep_ds.batch(1)\n",
    "        \n",
    "    for input_value, _ in rep_ds.take(100):\n",
    "        # Model has only one input so each data point has one element.\n",
    "        yield [input_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFLITE_FILE_PATH = \"brain_tumor_detector.tflite\"\n",
    "\n",
    "# optimize model and convert to tflite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# converter.representative_dataset = representative_data_gen\n",
    "tflite_quant_model = converter.convert()\n",
    "\n",
    "# save model as tflite\n",
    "with open(TFLITE_FILE_PATH, 'wb') as f:\n",
    "  f.write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze tflite model\n",
    "# tf.lite.experimental.Analyzer.analyze(model_content=tflite_quant_model, gpu_compatibility=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect tflite model \n",
    "interpreter = interpreter = tf.lite.Interpreter(TFLITE_FILE_PATH)\n",
    "input_details = interpreter.get_input_details()\n",
    "signatures = interpreter.get_signature_list()\n",
    "print(signatures)\n",
    "print(input_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signature = interpreter.get_signature_runner()\n",
    "print(signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test our tflite model\n",
    "pred_times = []\n",
    "\n",
    "if test_ds.__class__.__name__ == \"_BatchDataset\":\n",
    "    test_ds = test_ds.unbatch()\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for img, one_hot_label in test_ds:\n",
    "    label = tf.argmax(one_hot_label).numpy()\n",
    "    y_true.append(label)\n",
    "    t1 = time.time()\n",
    "    output = signature(input=tf.expand_dims(img, axis=0))\n",
    "    t2 = time.time()\n",
    "    pred = tf.squeeze(output[\"output\"], axis=0)\n",
    "    y_pred.append(tf.argmax(pred, axis=0).numpy())\n",
    "    pred_times.append(t2-t1)\n",
    "\n",
    "print(f\"average prediction time: {np.mean(pred_times)} seconds\")    \n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('/kaggle/working/brain-tumor-mri-dataset')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
